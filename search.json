[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "This data comes from a partnership between the Census Bureau, the NCHS (National Center for Health Statistics) and other federal agencies. It is a 20 minute online survey and is published every 2 weeks beginning on April 23, 2020. The specific data we are looking at from the August 20 - September 16, 2024 survey period and can be found on the Census Bureau website.\nThe survey was designed to complement the ability of the federal statistical system to rapidly respond and provide relevant information about the impact of COVID-19 in the United States. While the data was collected with a variety of federal agencies, collection was lead by the Census Bureau.\nThe data for the Household Pulse Survey was collected in response to COVID-19 in order to quickly respond and provide relevant information about the pandemic in the United States. This produces data representing social and economic matters affecting American households, which gets released in near real-time to determine state and federal action. For instance, this survey guiding emergency responses was fundamental, primarily during the pandemic’s peak. There are surveys that track similar data, but the data collection rate is not as frequent and the turnaround time is typically longer. There is existing research on this data. This includes a project evaluating the household pulse survey experiments, and focuses on how the survey can be more effective. Renee Reeves and Kayla Varela, the leads of this research, asked what implementations resulted in higher response rates, particularly contact strategies, e.g., text vs. email, short URL vs. long URL. Reeves and Varela determined that sending texts instead of emails, using shorter URLs containing census.gov over longer URLs, and sending only texts instead of both texts and emails generate more responses. There is a range of other research, including identifying the demographic characteristics of nonrespondents and respondents who select non-definitive response categories, as well as which demographics were more likely to respond to sexual orientation and gender identity (SOGI) questions.\n\n\nThe main issue with this data is that it is voluntary and self reported. This means that individuals may have different interpretations of the scales and numbers especially as it relates to levels of worry, anxiety, and loneliness. This is particularly the case for mental health data as there remains a lot of stigma around mental health, however, it is also harder to collect other more accurate data. Further demonstrating this problem, there are several questions that respondents skipped and did not answer.\nAdditionally, while people are randomly selected to participate, they have the option not to participate. Those that opt out of participating may be more distrustful of the government or too busy to take the time to fill out the survey. Both of these factors could be correlated with other variables in the survey. Respondents are also selected using household addresses. This automatically excludes people experiencing homelessness, as they may not have a household address.\nFurther, the data questioning has changed throughout the phases of the survey. Before Phase 3.2, the screening questions for mental health concerns asked “Over the last 7 days, how often have you been bothered by … having little interest or pleasure in doing things? Would you say not at all, several days, more than half the days, or nearly every day?” Phase 3.2 altered the question to “Over the last 14 days,” as opposed to the previously stated “7 days.” This could have changed responses given the timeframe is different — having a larger number of days n is more likely to create more varying data since there is more data to report. So, someone might respond “more than half the days” in a 14-day span, but “several days” in a 7-day span."
  },
  {
    "objectID": "data.html#the-data",
    "href": "data.html#the-data",
    "title": "Data",
    "section": "",
    "text": "This data comes from a partnership between the Census Bureau, the NCHS (National Center for Health Statistics) and other federal agencies. It is a 20 minute online survey and is published every 2 weeks beginning on April 23, 2020. The specific data we are looking at from the August 20 - September 16, 2024 survey period and can be found on the Census Bureau website.\nThe survey was designed to complement the ability of the federal statistical system to rapidly respond and provide relevant information about the impact of COVID-19 in the United States. While the data was collected with a variety of federal agencies, collection was lead by the Census Bureau.\nThe data for the Household Pulse Survey was collected in response to COVID-19 in order to quickly respond and provide relevant information about the pandemic in the United States. This produces data representing social and economic matters affecting American households, which gets released in near real-time to determine state and federal action. For instance, this survey guiding emergency responses was fundamental, primarily during the pandemic’s peak. There are surveys that track similar data, but the data collection rate is not as frequent and the turnaround time is typically longer. There is existing research on this data. This includes a project evaluating the household pulse survey experiments, and focuses on how the survey can be more effective. Renee Reeves and Kayla Varela, the leads of this research, asked what implementations resulted in higher response rates, particularly contact strategies, e.g., text vs. email, short URL vs. long URL. Reeves and Varela determined that sending texts instead of emails, using shorter URLs containing census.gov over longer URLs, and sending only texts instead of both texts and emails generate more responses. There is a range of other research, including identifying the demographic characteristics of nonrespondents and respondents who select non-definitive response categories, as well as which demographics were more likely to respond to sexual orientation and gender identity (SOGI) questions.\n\n\nThe main issue with this data is that it is voluntary and self reported. This means that individuals may have different interpretations of the scales and numbers especially as it relates to levels of worry, anxiety, and loneliness. This is particularly the case for mental health data as there remains a lot of stigma around mental health, however, it is also harder to collect other more accurate data. Further demonstrating this problem, there are several questions that respondents skipped and did not answer.\nAdditionally, while people are randomly selected to participate, they have the option not to participate. Those that opt out of participating may be more distrustful of the government or too busy to take the time to fill out the survey. Both of these factors could be correlated with other variables in the survey. Respondents are also selected using household addresses. This automatically excludes people experiencing homelessness, as they may not have a household address.\nFurther, the data questioning has changed throughout the phases of the survey. Before Phase 3.2, the screening questions for mental health concerns asked “Over the last 7 days, how often have you been bothered by … having little interest or pleasure in doing things? Would you say not at all, several days, more than half the days, or nearly every day?” Phase 3.2 altered the question to “Over the last 14 days,” as opposed to the previously stated “7 days.” This could have changed responses given the timeframe is different — having a larger number of days n is more likely to create more varying data since there is more data to report. So, someone might respond “more than half the days” in a 14-day span, but “several days” in a 7-day span."
  },
  {
    "objectID": "data.html#variables",
    "href": "data.html#variables",
    "title": "Data",
    "section": "Variables",
    "text": "Variables\nThe data included a wide variety of variables from veteran status to the impacts of natural disasters. However, we decided to make the data more manageable and focused by only examining the following variables that we were particularly interested in. We also took out variable where a large portion of the data was missing, including school type.\nWe kept basic descriptive variables of individuals such as Birth Year, State, Race and Ethnicity, Marital Status, Gender and Sexuality. We also wanted to include information about education and employment to see if that factored into mental health data. This includes level of education, school type (public, private, homeschooled) for children in the household, employment status, job loss and reason for not working. We also included if an individual was active duty or a veteran. Finally we examined the specific variables regarding mental health:\n\nAnxiousness\nWorry\nInterest\nFeeling Down\nChildren’s Mental Health Treatment (Need, if they received treatment, difficulty in finding treatment)\nSocial Support and Loneliness\nPrivate v Public Health Care\n\nOur full list of variables is used is as follows:\nBasic Descriptors Variables * Birth Year * Hispanic v Non-Hispanic * Race * Marital Status * Gender at Birth * Gender Identity * Sexuality * State * Household Income\nEducation and Employment * Education Level * Job Loss * Employment Status * Kind of Work * Reason not Working\nActive Duty and Veteran Status * Active Duty * Veteran\nMental Health * Anxious * Worry * Interest * Down * Children need for mental health treatment * Children receiving mental health treatment * Difficulty in obtaining treatment * Satisfaction with treatment * Social Support * Loneliness * Public vs Private Health Care"
  },
  {
    "objectID": "data.html#cleaning-the-data",
    "href": "data.html#cleaning-the-data",
    "title": "Data",
    "section": "Cleaning the Data",
    "text": "Cleaning the Data\nFirst, we load the data.\n\nsuppressMessages({\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n# install.packages(\"patchwork\")\nlibrary(patchwork) \ndata_unclean &lt;- read_csv(\"dataset/data_unclean.csv\") })\n\nOut of 220 variables (columns), we will keep 43 that we find may be useful. Furthermore, many variables contain the values “-88” and “-99”. “-88” indicates “Missing / Did not report”, which we interpret as NA. “-99” indicates “Question seen but category not selected”, which we convert to 0. This makes histograms concise (and makes regression easier, although that is not our focus).\n\nsuppressWarnings(suppressMessages({\n  data_unclean &lt;- read_csv(\"dataset/data_unclean.csv\", na = c(\"-88\"))\n}))\ncolumns = c(\"TBIRTH_YEAR\", \"RHISPANIC\", \"RRACE\", \"EEDUC\", \"MS\", \"EGENID_BIRTH\", \"RGENID_DESCRIBE\", \"SEXUAL_ORIENTATION_RV\", \"ENRPUBCHK\", \"ENRPRVCHK\", \"ENRHMSCHK\", \"ACTVDUTY1\", \"ACTVDUTY2\", \"ACTVDUTY3\", \"ACTVDUTY4\", \"ACTVDUTY5\", \"VETERAN1\", \"VETERAN2\", \"VETERAN3\", \"VETERAN4\", \"VETERAN5\", \"WRKLOSSRV\", \"ANYWORK\", \"KINDWORK\", \"RSNNOWRKRV\", \"ANXIOUS\", \"WORRY\", \"INTEREST\", \"DOWN\", \"MHLTH_NEED\", \"MHLTH_GET\", \"MHLTH_SATISFD\", \"MHLTH_DIFFCLT\", \"SOCIAL1\", \"SOCIAL2\", \"PRIVHLTH\", \"PUBHLTH\", \"EST_ST\", \"INCOME\", \"SUPPORT1\", \"SUPPORT2\", \"SUPPORT3\", \"SUPPORT4_RV\")\n \ndata_unclean = data_unclean[columns]\ndata_unclean[data_unclean == -99] = 0\n\nNext, we see how many values are NA in each variable.\n\ncolSums(is.na(data_unclean[columns]))\n\n          TBIRTH_YEAR             RHISPANIC                 RRACE \n                    0                     0                     0 \n                EEDUC                    MS          EGENID_BIRTH \n                    0                   120                     0 \n      RGENID_DESCRIBE SEXUAL_ORIENTATION_RV             ENRPUBCHK \n                  120                   120                 37071 \n            ENRPRVCHK             ENRHMSCHK             ACTVDUTY1 \n                37071                 37071                   120 \n            ACTVDUTY2             ACTVDUTY3             ACTVDUTY4 \n                  120                   120                   120 \n            ACTVDUTY5              VETERAN1              VETERAN2 \n                  120                   912                   912 \n             VETERAN3              VETERAN4              VETERAN5 \n                  912                   912                   912 \n            WRKLOSSRV               ANYWORK              KINDWORK \n                  120                   120                 22126 \n           RSNNOWRKRV               ANXIOUS                 WORRY \n                29685                   120                   120 \n             INTEREST                  DOWN            MHLTH_NEED \n                  120                   120                 37162 \n            MHLTH_GET         MHLTH_SATISFD         MHLTH_DIFFCLT \n                48718                 49021                 48718 \n              SOCIAL1               SOCIAL2              PRIVHLTH \n                  726                   726                     0 \n              PUBHLTH                EST_ST                INCOME \n                    0                     0                  6519 \n             SUPPORT1              SUPPORT2              SUPPORT3 \n                 1362                  1362                  1362 \n          SUPPORT4_RV \n                 1362 \n\n\nThe output indicates many NA (including “-88”) values.\nHowever, we believe the data is already quite clean, as many questions are only given to some survey participants. For example, MHLTH_DIFFCLT represents a question asking whether the survey participant has difficulty finding mental health treatment for their child(ren). Evidently, only a small fraction of the 51280 participants have answered this question.\n\nsum(!is.na(data_unclean$MHLTH_DIFFCLT))\n\n[1] 2562\n\n\nThe histogram below plots the responses to MHLTH_DIFFCLT against the birth year of participants.\n\n# https://www.statology.org/r-convert-numeric-to-factor/\nplot = ggplot(\n  data = data_unclean[!is.na(data_unclean$MHLTH_DIFFCLT),],\n  mapping = aes(x = TBIRTH_YEAR, fill = as.factor(MHLTH_DIFFCLT))\n) + geom_histogram() + ggtitle(\"MHLTH_DIFFCLT vs birth year\",\n                               subtitle=\"MHLTH_DIFFCLT: A participant's difficulty finding mental health treatment for their child(ren)\")\n \nplot\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nHere, 0: Question seen but category not selected 1: Not difficult 2: Somewhat difficult 3: Very difficult 4: Unable to get treatment due to difficulty 5: Did not try to get treatment\nAfterwards, we will rename each of the columns to be more intuitive.\n\ndata_unclean &lt;- data_unclean |&gt;\n  rename(Birth_Year = TBIRTH_YEAR, Hispanic = RHISPANIC, Race = RRACE, Educational_Attainment = EEDUC, Marital_Status = MS, Gender_at_Birth = EGENID_BIRTH, Gender_Identity = RGENID_DESCRIBE, Sexuality = SEXUAL_ORIENTATION_RV, Public_School = ENRPUBCHK, Private_School = ENRPRVCHK, Home_School = ENRHMSCHK, Not_Currently_Serving_in_US_Armed_Forces = ACTVDUTY1, Serving_on_Active_Duty = ACTVDUTY2, Serving_in_Reserve_or_National_Guard = ACTVDUTY3, Spouse_Serving_on_Active_Duty = ACTVDUTY4, Spouse_Serving_in_Reserve_or_National_Guard = ACTVDUTY5, Not_Served_in_US_Armed_Forces = VETERAN1, Served_on_Active_Duty = VETERAN2, Served_in_Reserve_or_National_Guard = VETERAN3, Spouse_Served_on_Active_Duty = VETERAN4, Spouse_Served_in_Reserve_or_National_Guard = VETERAN5, Job_Loss = WRKLOSSRV, Employment_Status = ANYWORK, Kind_of_Work = KINDWORK, Reason_Not_Working = RSNNOWRKRV, Anxious_Frequency = ANXIOUS, Worry_Frequency = WORRY, Little_Interest_Frequency = INTEREST, Depressed_Frequency = DOWN, Children_Need_for_Mental_Health_Treatment = MHLTH_NEED, Children_Receive_Mental_Health_Treatment = MHLTH_GET, Satisfaction_with_Treatment = MHLTH_SATISFD, Difficulty_getting_Treatment = MHLTH_DIFFCLT, Social_and_Emotional_Support = SOCIAL1, Lonely_Frequency = SOCIAL2, Private_Health_Insurance = PRIVHLTH, Public_Health_Insurance = PUBHLTH, State_Living_in = EST_ST, Household_Income = INCOME, Family_Friends_Neighbors_Phonecall_Frequency = SUPPORT1, Friends_Relative_Get_Together_Frequency = SUPPORT2, Church_Religious_Services_Attendance_Frequency = SUPPORT3, Club_Organization_Meetings_Attendance_Frequency = SUPPORT4_RV)\n\nFinally, let’s save data_unclean as an .rds file.\n\nwrite_rds(data_unclean, \"dataset/data_clean.rds\")"
  },
  {
    "objectID": "data.html#second-data-set",
    "href": "data.html#second-data-set",
    "title": "Data",
    "section": "Second Data Set",
    "text": "Second Data Set\nWe also used health service information from the Health Resources and Services Administration. This data shows the number of different health care providers across different states. As we are mainly focused on mental health, we decided to only use the columns that discussed the number of psychologists, social workers, and counselors per state.\n\nsuppressWarnings(suppressMessages({\n  care_data &lt;- read_csv(\"dataset/care_data.csv\")\n}))\n\ncare_data_sum &lt;- care_data |&gt;\n  reframe(st_abbrev, psychol_21, socwk_21, conslrs_21, popn_pums_21)\n\nstate_names &lt;- c(\n  AL = \"alabama\",\n  AK = \"alaska\",\n  AZ = \"arizona\",\n  AR = \"arkansas\",\n  CA = \"california\",\n  CO = \"colorado\",\n  CT = \"connecticut\",\n  DE = \"delaware\",\n  FL = \"florida\",\n  GA = \"georgia\",\n  HI = \"hawaii\",\n  ID = \"idaho\", \n  IL = \"illinois\",\n  IN = \"indiana\",\n  IA = \"iowa\",\n  KS = \"kansas\",\n  KY = \"kentucky\",\n  LA = \"louisiana\",\n  ME = \"maine\",\n  MD = \"maryland\",\n  MA = \"massachusetts\",\n  MI = \"michigan\",\n  MN = \"minnesota\",\n  MS = \"mississippi\",\n  MO = \"missouri\",\n  MT = \"montana\",\n  NE = \"nebraska\",\n  NV = \"nevada\",\n  NH = \"new hampshire\",\n  NJ = \"new jersey\",\n  NM = \"new mexico\",\n  NY = \"new york\",\n  NC = \"north carolina\",\n  ND = \"north dakota\",\n  OH = \"ohio\",\n  OK = \"oklahoma\",\n  OR = \"oregon\",\n  PA = \"pennsylvania\",\n  RI = \"rhode island\",\n  SC = \"south carolina\",\n  SD = \"south dakota\",\n  TN = \"tennessee\",\n  TX = \"texas\",\n  UT = \"utah\",\n  VT = \"vermont\",\n  VA = \"virginia\",\n  WA = \"washington\",\n  WV = \"west virginia\",\n  WI = \"wisconsin\",\n  WY = \"wyoming\"\n)\n\ncare_data_sum &lt;- care_data_sum |&gt;\n  mutate(region = recode(st_abbrev, !!!state_names))\n\nwrite_csv(care_data_sum, \"dataset/care_data_sum.csv\")"
  },
  {
    "objectID": "data.html#page-info",
    "href": "data.html#page-info",
    "title": "Data",
    "section": "Page Info",
    "text": "Page Info"
  },
  {
    "objectID": "data.html#where-to-keep-data",
    "href": "data.html#where-to-keep-data",
    "title": "Data",
    "section": "Where to keep data?",
    "text": "Where to keep data?\nBelow 50mb: In dataset folder\nAbove 50mb: In dataset_ignore folder. This folder will be ignored by git so you’ll have to manually sync these files across your team.\n\nSharing your data\nFor small datasets (&lt;50mb), you can use the dataset folder that is tracked by github. Add the files just like you would any other file.\nIf you create a folder named data this will cause problems.\nFor larger datasets, you’ll need to create a new folder in the project root directory named dataset-ignore. This will be ignored by git (based off the .gitignore file in the project root directory) which will help you avoid issues with Github’s size limits. Your team will have to manually make sure the data files in dataset-ignore are synced across team members.\nYour load_and_clean_data.R file is how you will load and clean your data. Here is a an example of a very simple one.\n\nsource(\n  \"scripts/load_and_clean_data.R\",\n  echo = TRUE # Use echo=FALSE or omit it to avoid code output  \n)\n\n\n&gt; library(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n&gt; loan_data &lt;- read_csv(here::here(\"dataset\", \"loan_refusal.csv\"))\n\n\nRows: 20 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): bank\ndbl (4): min, white, himin, hiwhite\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n&gt; loan_data_clean &lt;- pivot_longer(loan_data, 2:5, names_to = \"group\", \n+     values_to = \"refusal_rate\")\n\n&gt; write_rds(loan_data_clean, file = here::here(\"dataset\", \n+     \"loan_refusal_clean.rds\"))\n\n\nYou should never use absolute paths (eg. /Users/danielsussman/path/to/project/ or C:\\MA415\\\\Final_Project\\).\nYou might consider using the here function from the here package to avoid path problems.\n\n\nLoad and clean data script\nThe idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them. This file might create a derivative data set that you then use for your subsequent analysis. Note that you don’t need to run this script from every post/page. Instead, you can load in the results of this script, which could be plain text files or .RData files. In your data page you’ll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes. To link to this file, you can use [cleaning script](/scripts/load_and_clean_data.R) wich appears as cleaning script."
  },
  {
    "objectID": "data.html#rubric-on-this-page",
    "href": "data.html#rubric-on-this-page",
    "title": "Data",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nDescribe where/how to find data.\n\nYou must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\nWhy was the data collected/curated? Who put it together? (This is important, if you don’t know why it was collected then that might not be a good dataset to look at.\n\nDescribe the different data files used and what each variable means.\n\nIf you have many variables then only describe the most relevant ones and summarize the rest.\n\nDescribe any cleaning you had to do for your data.\n\nYou must include a link to your load_and_clean_data.R file.\nRrename variables and recode factors to make data more clear.\nAlso, describe any additional R packages you used outside of those covered in class.\nDescribe and show code for how you combined multiple data files and any cleaning that was necessary for that.\nSome repetition of what you do in your load_and_clean_data.R file is fine and encouraged if it helps explain what you did.\n\nOrganization, clarity, cleanliness of the page\n\nMake sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\nThis page should be self-contained."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "## Main Questions - How does access to mental health services change based on factors such as income, education, and race? - How do measures of mental wellbeing (levels of worry, anxiety, etc.) change based on age, income, education, and race? - How does veteran/active duty status effect mental health?\nThis comes from the file analysis.qmd.\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 7, 2024 at 11:59pm.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 6\n\n\n“Exploring the Joint Data”\n\n\n\n\n\n\n\n\nNov 17, 2024\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 5\n\n\nDescriptions of Combined Datasets\n\n\n\n\n\n\n\n\nNov 9, 2024\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 4\n\n\nLinear Modeling Test & Final Cleaning\n\n\n\n\n\n\n\n\nNov 6, 2024\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 3\n\n\nData Cleaning and Exploration\n\n\n\n\n\n\n\n\nOct 27, 2024\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 2\n\n\nFinalized Data Set Research and Initial Cleaning\n\n\n\n\n\n\n\n\nOct 18, 2024\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 1\n\n\nExploring Three Data Sets\n\n\n\n\n\n\n\n\nOct 9, 2024\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post. \n\n\n\n\n\nFeb 23, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting. \n\n\n\n\n\nFeb 21, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-11-17-blog-post-6/blog-post-6.html",
    "href": "posts/2024-11-17-blog-post-6/blog-post-6.html",
    "title": "Blog Post 6",
    "section": "",
    "text": "This week, we finished merging our two datasets. We had some initial issues because we had to make adjustments to our primary dataset by assigning new values to a column. The column “EST_ST,” representing the state that the participants live in, had values 1-50 to reflect each state. However, the dataset that we are merging (healthcare accessibility data) had the states written out to reflect where participants lived, so we had to convert values (Alabama = 1, Alaska = 2, …). Once this was changed, we were able to merge the data and perform initial analyses.\nWe spent the majority of this week fixing the errors in the merging of our data. Our goal for the coming week is to continue working on analyses of the combined data. Eventually, our plan is to create a series of maps to compare states.\nWe created some plots to explore what the relationship between our variables that are new to the data: psychol_21 (number of psychologists in the state), socwk_21 (number of social workers in the state), conslrs_21 (number of counselors in the state). We faceted 3 plots where these were the x values and the y were the average mental health values grouped by state. The results are below:\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nIt seems that there is a slight increase of mental health values as the number of specialists increase. These findings are important because they show that a higher number of specialists benefits the mental health of the state population, although the increase is not very high. We will continue to work with this data in order to find more insight between the number of specialists and the variables of importance in our original dataset."
  },
  {
    "objectID": "posts/2024-11-09-blog-post-5/blog-post-5.html",
    "href": "posts/2024-11-09-blog-post-5/blog-post-5.html",
    "title": "Blog Post 5",
    "section": "",
    "text": "We looked into various datasets that could be joined with ours, allowing a more in-depth analysis. Some of our ideas included joining datasets concerning COVID-19, healthcare accessibility, unemployment rates, and weather, all joined on either date or region. The COVID-19 dataset could account for any anomalies within our data during the pandemic’s peak, specifically recognizing changes in unemployment status and income, which may have impacted mental health. Healthcare accessibility could influence mental health, as proximity to care facilities affects the frequency of seeing medical providers. Unemployment rates by region could illustrate which places have the highest and lowest unemployment rates, and from there, we could compare which groups of people are most likely to reside in certain regions and whether their demographics impact or are impacted by other variables. Lastly, weather data could find correlations between time of year and poor mental health, potentially showing the effects of seasonal depression. By accounting for these outside variables (the COVID-19 pandemic, accessibility to healthcare facilities, unemployment status by location, and seasonal depression), we could train our model better to recognize these influences.\nWe ultimately chose to assess healthcare accessibility data, specifically the 2022-2023 State and National Level Data. One challenge with this dataset is that it has 6000 variables, but we have selected to examine specific access to providers, like social workers, primary care, psychologists, child psychiatrists, and a few others. We are merging this data on “state” to determine how healthcare accessibility varies by region and impacts mental health. We have not yet finished combining the dataset, so we do not have any preliminary analyses. Our next step is to clean the data, and from there, we can determine any initial findings.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nAbove are a few histograms that outline the distribution of the proportion of # of each type of specialist per person. The distributions seem to be very similar, with high counts near the left side of the range, and a right-skewed shape. This shows us that many of the proportions of specialists in each state does not seem to vary much, however there are some states with proportions of specialists that are much higher than others. We will continue to analyze this data to see if there are connections that we can create between healthcare accessibility and the other mental health statistics."
  },
  {
    "objectID": "posts/2024-10-27 blogpost3/blogpost3.html",
    "href": "posts/2024-10-27 blogpost3/blogpost3.html",
    "title": "Blog Post 3",
    "section": "",
    "text": "During this week, we continued to clean and explore the Household Pulse Survey data that we chose. Within the cleaning procedure, we have removed all columns that do not align with what we want to focus on, which is mental health. We reduced the column size from about 220 to 43, making the data much more manageable for our data processing. Furthermore, we have modified the source’s null values, which were -88, into NULL values to change the data into a form that we are comfortable with.\nNow that we have cleaned our data, we are also able to do some exploratory data analysis to see some initial trends and potential biases within our data. Our data cleaning and exploration can be found in the data segment of the project, but below is one of our most interesting graphs:\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThis is a graph that shows the distribution of a participant’s birth year, and while also showing the difficulty of finding mental health treatment for their children. The first thing to notice is that most of the birth years are centralized between 1970 - 1990, and this is probably because most of the people who are considered parents within the survey were born between 1970-1990. The colors that represent the difficulty of finding mental health shows high counts of 1 and 2, implying that it is not very difficult to find mental health resources for children. We plan on working on analyzing mental health data, so these preliminary graphs can help us understand some things about the data that are not visible from just looking at the table."
  },
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post. You’ll want to render your post to see what it will look like on the site.\n\nEvery time you want to make a new post, you can repeat step 2 above.\nWhen you want to publish your progress, follow steps 4-7 from Customize your site.\n\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "posts/2024-10-18-blog-post-2/blog-post-2.html",
    "href": "posts/2024-10-18-blog-post-2/blog-post-2.html",
    "title": "Blog Post 2",
    "section": "",
    "text": "This past week, we finalized our data set, the Household Pulse Survey, and have been focused on fine-tuning our data. We had an issue last week where our blog post wasn’t published, despite committing it to our main page, which we resolved during class. Because Professor Sussman wasn’t able to view our first blog post where we pitched our dataset, we ran it by him in class and he approved. We are also mindful that there are potential biases from this dataset and other research has shown how certain question orderings impact responses. Despite this, we are continuing to explore this dataset because it’s guided federal emergency responses during the peak of COVID-19, meaning it’s played a significant role in policy."
  },
  {
    "objectID": "posts/2024-10-18-blog-post-2/blog-post-2.html#data-for-equity",
    "href": "posts/2024-10-18-blog-post-2/blog-post-2.html#data-for-equity",
    "title": "Blog Post 2",
    "section": "Data for Equity",
    "text": "Data for Equity\n\nBeneficence:\nOne of the principles for advancing equitable data practice is to “be transparent about the limits of the data”. This is relevant to our data because the data from the Household Pulse Survey is voluntary and self-reported, possibly leading to different interpretations for each question, especially ones regarding mental health. This principle entails adding disclaimers to the data analysis. Without transparency, the analysis could be misinterpreted and abused.\n\n\nJustice\nAnother principle is to “return data and research results to community members in a form they can use”. This is important so members who were surveyed for the Household Pulse Survey can benefit and learn from the data collection. We will do this for our data by presenting the analysis in an accessible and organized format on the group project website."
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (For your first blog post, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext time, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2024-10-09-blogpost1/blogpost1.html",
    "href": "posts/2024-10-09-blogpost1/blogpost1.html",
    "title": "Blog Post 1",
    "section": "",
    "text": "Three data sets that we are interested in working on are Cardiovascular Disease Mortality, Household Pulse Survey, and Drug Overdose Death Rates."
  },
  {
    "objectID": "posts/2024-10-09-blogpost1/blogpost1.html#cardiovascular-disease-mortality-dataset",
    "href": "posts/2024-10-09-blogpost1/blogpost1.html#cardiovascular-disease-mortality-dataset",
    "title": "Blog Post 1",
    "section": "Cardiovascular Disease Mortality | Dataset",
    "text": "Cardiovascular Disease Mortality | Dataset\nThis dataset provided by the U.S. Department of Health & Human Services contains county-level estimates of hypertension-related cardiovascular disease (CVD) from 2000 to 2019, as well as two 10-year trends (2000-2010, 2010-2019), by age group, race/ethnicity, and sex. Each year and 10-year period contains 50,176 rows. About half of the values for “Data_Value” are na (empty), possibly because some demographics are not represented in state populations.\nWe may be more interested in looking at individual years, as 1. the total dataset amounts to over 1 million rows, and 2. the rows concerning 10-year trends are calculated through a Bayesian model and do not represent raw data."
  },
  {
    "objectID": "posts/2024-10-09-blogpost1/blogpost1.html#household-pulse-survey-dataset",
    "href": "posts/2024-10-09-blogpost1/blogpost1.html#household-pulse-survey-dataset",
    "title": "Blog Post 1",
    "section": "Household Pulse Survey | Dataset",
    "text": "Household Pulse Survey | Dataset\nThe Household Pulse Survey surveys households across the country on a variety of different measures of wellbeing including mental health, food access, and housing. This survey has been collected since 2020 and is collected using a two weeks on, two weeks off approach. This means that there are several data sets spanning the past four years. Looking at one survey period, there are 51281 rows and 163 columns.\nThe data is collected to get quick information on the social and economic wellbeing of households across the country. Looking at this data we could examine changes in mental health across different states and over the past four years. We could also look at different economic factors for example housing and food insecurity across time and regions. There are several potential challenges with this data set. First, since this survey is distributed so frequently, there are close to 60 data sets per year which may be difficult to sift through. Additionally, as the data looks at a wide range of factors it may be difficult to focus on one or two."
  },
  {
    "objectID": "posts/2024-10-09-blogpost1/blogpost1.html#drug-overdose-death-rates-dataset",
    "href": "posts/2024-10-09-blogpost1/blogpost1.html#drug-overdose-death-rates-dataset",
    "title": "Blog Post 1",
    "section": "Drug Overdose Death Rates | Dataset",
    "text": "Drug Overdose Death Rates | Dataset\nThe Centers for Disease Control and Prevention documented drug overdose death rates based on drug type, sex, age, race, and Hispanic origin. The dataset dates from 1999 to 2018, with 6228 rows and 16 columns. The CDC has released datasets containing this information annually since 1999 and has data up to 2019, but isn’t publicly available on their website.\nWe are hoping to analyze the disparities in drug overdoses based on race from the 20 years of data collection. From the data, we could also determine which races have the highest access (potentially finding what race the majority of the youngest age, documented as “Under 15 years,” drug overdoses occur) to certain drugs e.g. heroin and natural and semisynthetic opioids, and the death rates associated with each drug. The time progression can show trends in access to drugs and deaths, although a possible challenge is that we might see rising numbers in deaths solely as a byproduct of the growing population. This might mean we need to standardize the data with respect to population count. Another concern is there are 11 values in the “STUB_LABEL” column, so we may need to group columns to visualize the effects of race on drug overdose better."
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html",
    "href": "posts/2023-12-20-examples/examples.html",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "href": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2024-11-06-blog-post-4/blog-post-4.html",
    "href": "posts/2024-11-06-blog-post-4/blog-post-4.html",
    "title": "Blog Post 4",
    "section": "",
    "text": "During this week, we have further cleaned the data to prepare it for modeling and analysis. Some of the changes we have made to the data are to make the data more comprehensive without a data dictionary. For example, the column ACTVDUTY1 represents whether one or one’s spouse currently is not active in the U.S. Armed Forces. We changed the column name to Not_Currently_Serving_in_US_Armed_Forces. We have also changed the row data since our row data was just numbers that represented values. For example, for the row RHISPANIC, which has been renamed to Hispanic, the values within the column is either 1 or 2, based on whether the person is hispanic or not. We have changed it to Yes or No to help us understand the data more efficiently.\nOther than cleaning, we have begun putting effort into modeling and analysis. We have created a new column that aggregates the values within the mental health columns such as anxiety, worry, feeling down, and interest. This will help us understand the effect of certain variables on mental health overall. With this new column, we were able to compare it to household income using the lm() function in R. The results of our model are interesting, and some of our results can be seen below with our Normal QQ plot:\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\n\nThis plot shows that our distribution of residuals are not normally distributed. Within the middle quantiles, the residuals follow the normal distribution, but the farther quantiles from the mean show a difference from the normal distribution. These differences imply that within the farther quantiles, the data says very similar in their residuals, signaling that there may be some sort of boundaries in our data that the data cannot exceed."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Group 11. The members of this team are below."
  },
  {
    "objectID": "about.html#brianna-li",
    "href": "about.html#brianna-li",
    "title": "About",
    "section": "Brianna Li",
    "text": "Brianna Li\nBrianna is a senior studying Math and Computer Science, and is from Boston, MA."
  },
  {
    "objectID": "about.html#bridget-griffith",
    "href": "about.html#bridget-griffith",
    "title": "About",
    "section": "Bridget Griffith",
    "text": "Bridget Griffith\nBridget is a senior studying Political Science with minors in Statistics and Economics. She is originally from Takoma Park, MD."
  },
  {
    "objectID": "about.html#brenton-mac",
    "href": "about.html#brenton-mac",
    "title": "About",
    "section": "Brenton Mac",
    "text": "Brenton Mac\nBrenton is a junior majoring in Data Science. He is from Framingham, MA."
  },
  {
    "objectID": "about.html#taiyo-nakai",
    "href": "about.html#taiyo-nakai",
    "title": "About",
    "section": "Taiyo Nakai",
    "text": "Taiyo Nakai\nTaiyo is a senior studying Data Science with a minor in Statistics. He is originally from Malden, MA."
  },
  {
    "objectID": "about.html#nicole-liu",
    "href": "about.html#nicole-liu",
    "title": "About",
    "section": "Nicole Liu",
    "text": "Nicole Liu\nNicole is a junior majoring in Data Science and minoring in Innovation & Entrepreneurship. She is from Irvine, CA.\n\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.Rmd.\nThink of this page as your 538/Upshot style article. This means that you should try to tell a story through the data and your analysis. Read articles from those sites and similar sites to get a feeling for what they are like. Try to write in the style of a news or popular article. Importantly, this page should be geared towards the general public. You shouldn’t assume the reader understands how to interpret a linear regression or a complicated plot. Focus on interpretation and visualizations."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nInteractive component\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions?\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  }
]